# ğŸ“° Scripts de AutomatizaciÃ³n de Noticias

Este directorio contiene todos los scripts necesarios para automatizar la adiciÃ³n de noticias de desarrollo al blog.

## ğŸ“ Archivos

| Archivo | DescripciÃ³n |
|---------|-------------|
| `news-scraper.py` | Script principal que extrae noticias y genera posts MDX |
| `news-config.json` | ConfiguraciÃ³n personalizable del scraper |
| `news-template.mdx` | Template para generar posts MDX |
| `test-news-scraper.py` | Script de pruebas para verificar funcionamiento |
| `setup-news-automation.sh` | Script de configuraciÃ³n inicial (Linux/Mac) |
| `processed_news.json` | Tracking de noticias ya procesadas (generado automÃ¡ticamente) |

## ğŸš€ Uso RÃ¡pido

### 1. Instalar dependencias

```bash
pip install requests feedparser beautifulsoup4 lxml
```

### 2. Ejecutar pruebas

```bash
python scripts/test-news-scraper.py
```

### 3. Ejecutar scraper manualmente

```bash
python scripts/news-scraper.py
```

### 4. Configurar GitHub Actions

El workflow en `.github/workflows/update-news-blog.yml` se ejecutarÃ¡ automÃ¡ticamente.

## âš™ï¸ ConfiguraciÃ³n

### Personalizar fuentes RSS

Edita `news-config.json`:

```json
{
  "rss_feeds": [
    {
      "name": "Dev.to",
      "url": "https://dev.to/feed",
      "category": "Desarrollo Web",
      "enabled": true,
      "priority": 1
    }
  ]
}
```

### Ajustar filtros de contenido

```json
{
  "keywords": {
    "required": ["javascript", "react", "python"],
    "optional": ["css", "html", "api"],
    "exclude": ["job", "hiring", "career"]
  }
}
```

### Modificar lÃ­mites

```json
{
  "settings": {
    "max_posts_per_run": 3,
    "max_posts_per_source": 2,
    "rate_limit_delay": 0.5
  }
}
```

## ğŸ§ª Testing

### Ejecutar todas las pruebas

```bash
python scripts/test-news-scraper.py
```

### Probar una fuente especÃ­fica

Modifica temporalmente `news-config.json` para incluir solo una fuente y ejecuta:

```bash
python scripts/news-scraper.py
```

## ğŸ”§ Troubleshooting

### Error: "No module named 'requests'"

```bash
pip install requests feedparser beautifulsoup4 lxml
```

### Error: "Permission denied"

```bash
# Linux/Mac
chmod +x scripts/news-scraper.py

# Windows - no es necesario
```

### Posts no se generan

1. Verifica que las fuentes RSS estÃ©n activas
2. Revisa los logs de GitHub Actions
3. Confirma que `processed_news.json` no estÃ© bloqueando contenido

### Contenido no relevante

1. Ajusta palabras clave en `news-config.json`
2. Modifica filtros de contenido
3. Desactiva fuentes problemÃ¡ticas temporalmente

## ğŸ“Š Monitoreo

### Logs del scraper

El script imprime logs detallados durante la ejecuciÃ³n:

```
ğŸš€ Iniciando scraper de noticias de desarrollo...
ğŸ“¡ Obteniendo noticias de Dev.to...
âœ… Creado: nueva-noticia-20240115.mdx
ğŸ‰ Proceso completado. Se crearon 2 nuevos posts.
```

### Archivo de tracking

`processed_news.json` mantiene un registro de todas las noticias procesadas para evitar duplicados.

## ğŸ”„ Flujo de Trabajo

1. **GitHub Action se ejecuta** (diariamente)
2. **Scraper obtiene noticias** de feeds RSS
3. **Filtra contenido relevante** usando palabras clave
4. **Verifica duplicados** usando sistema de tracking
5. **Genera archivos MDX** usando template
6. **Commit y push** automÃ¡tico

## ğŸ“š DocumentaciÃ³n Completa

Para documentaciÃ³n detallada, consulta:
- [NEWS_AUTOMATION_SETUP.md](../NEWS_AUTOMATION_SETUP.md) - GuÃ­a completa de configuraciÃ³n
- [GitHub Action](../.github/workflows/update-news-blog.yml) - Workflow de automatizaciÃ³n

## ğŸ¤ Contribuir

Para agregar nuevas fuentes o mejorar el scraper:

1. Edita `news-config.json` para agregar fuentes
2. Modifica `news-template.mdx` para personalizar formato
3. Ajusta `news-scraper.py` para nuevas funcionalidades
4. Ejecuta `test-news-scraper.py` para verificar cambios
5. Haz commit y push de los cambios

---

**Â¿Necesitas ayuda?** Abre un issue en el repositorio.
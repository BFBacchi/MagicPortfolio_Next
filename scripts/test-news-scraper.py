#!/usr/bin/env python3
"""
Script de prueba para el scraper de noticias
"""

import sys
import os
import importlib.util

# Agregar el directorio de scripts al path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Importar el mÃ³dulo news-scraper dinÃ¡micamente
spec = importlib.util.spec_from_file_location("news_scraper", "scripts/news-scraper.py")
news_scraper = importlib.util.module_from_spec(spec)
spec.loader.exec_module(news_scraper)

NewsScraper = news_scraper.NewsScraper
import json

def test_scraper():
    """Probar el scraper con configuraciÃ³n de prueba"""
    print("ğŸ§ª Iniciando pruebas del scraper de noticias...")
    
    # Crear instancia del scraper
    scraper = NewsScraper()
    
    # Configurar para modo de prueba
    scraper.max_posts_per_run = 1  # Solo 1 post para prueba
    
    print("\nğŸ“¡ Probando obtenciÃ³n de noticias...")
    
    try:
        # Obtener noticias
        news_items = scraper.fetch_rss_news()
        print(f"âœ… Se obtuvieron {len(news_items)} noticias")
        
        if news_items:
            # Mostrar primera noticia como ejemplo
            first_news = news_items[0]
            print(f"\nğŸ“° Ejemplo de noticia:")
            print(f"   TÃ­tulo: {first_news['title'][:50]}...")
            print(f"   Fuente: {first_news['source']}")
            print(f"   CategorÃ­a: {first_news['category']}")
            print(f"   URL: {first_news['url']}")
            
            # Probar generaciÃ³n de MDX
            print(f"\nğŸ“ Probando generaciÃ³n de MDX...")
            content, slug = scraper.generate_mdx_content(first_news)
            print(f"âœ… MDX generado exitosamente")
            print(f"   Slug: {slug}")
            print(f"   Longitud del contenido: {len(content)} caracteres")
            
            # Mostrar preview del frontmatter
            frontmatter_lines = content.split('\n')[:10]
            print(f"\nğŸ“‹ Preview del frontmatter:")
            for line in frontmatter_lines:
                print(f"   {line}")
            
        else:
            print("âš ï¸  No se obtuvieron noticias para probar")
            
    except Exception as e:
        print(f"âŒ Error durante la prueba: {e}")
        return False
    
    print(f"\nğŸ‰ Pruebas completadas exitosamente!")
    return True

def test_config():
    """Probar la configuraciÃ³n"""
    print("\nâš™ï¸ Probando configuraciÃ³n...")
    
    config_file = "scripts/news-config.json"
    if os.path.exists(config_file):
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        print(f"âœ… ConfiguraciÃ³n cargada:")
        print(f"   Fuentes RSS: {len(config['rss_feeds'])}")
        print(f"   MÃ¡ximo posts por ejecuciÃ³n: {config['settings']['max_posts_per_run']}")
        
        enabled_feeds = [f for f in config['rss_feeds'] if f.get('enabled', True)]
        print(f"   Fuentes activas: {len(enabled_feeds)}")
        
        for feed in enabled_feeds:
            print(f"     - {feed['name']} ({feed['category']})")
    else:
        print("âš ï¸  Archivo de configuraciÃ³n no encontrado")

if __name__ == "__main__":
    print("ğŸš€ Iniciando pruebas del sistema de automatizaciÃ³n de noticias")
    print("=" * 60)
    
    # Probar configuraciÃ³n
    test_config()
    
    # Probar scraper
    success = test_scraper()
    
    print("\n" + "=" * 60)
    if success:
        print("âœ… Todas las pruebas pasaron exitosamente!")
        print("\nğŸ“‹ PrÃ³ximos pasos:")
        print("1. Revisa la configuraciÃ³n en scripts/news-config.json")
        print("2. Ejecuta el scraper completo: python scripts/news-scraper.py")
        print("3. El GitHub Action se ejecutarÃ¡ automÃ¡ticamente")
    else:
        print("âŒ Algunas pruebas fallaron. Revisa los errores arriba.")
        sys.exit(1)

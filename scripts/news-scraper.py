#!/usr/bin/env python3
"""
Script para extraer noticias de desarrollo y generar archivos MDX
"""

import requests
import feedparser
import json
import os
import re
from datetime import datetime, timedelta
from pathlib import Path
import hashlib
import time

class NewsScraper:
    def __init__(self):
        self.base_dir = Path(__file__).parent.parent
        self.posts_dir = self.base_dir / "src" / "app" / "noticias" / "posts"
        self.processed_file = self.base_dir / "scripts" / "processed_news.json"
        self.max_posts_per_run = 3  # M√°ximo 3 posts por ejecuci√≥n
        
        # Fuentes RSS en espa√±ol
        self.rss_feeds = [
            {
                "name": "Dev.to Espa√±ol",
                "url": "https://dev.to/feed/tag/spanish",
                "category": "Desarrollo Web"
            },
            {
                "name": "FreeCodeCamp Espa√±ol",
                "url": "https://www.freecodecamp.org/espanol/news/rss.xml",
                "category": "Programaci√≥n"
            },
            {
                "name": "Platzi Blog",
                "url": "https://platzi.com/blog/feed/",
                "category": "Educaci√≥n Tech"
            },
            {
                "name": "C√≥digo Facilito",
                "url": "https://codigofacilito.com/articulos.rss",
                "category": "Tutoriales"
            },
            {
                "name": "OpenWebinars",
                "url": "https://openwebinars.net/blog/feed/",
                "category": "Tecnolog√≠a"
            },
            {
                "name": "Genbeta",
                "url": "https://www.genbeta.com/feed",
                "category": "Tecnolog√≠a"
            },
            {
                "name": "Xataka",
                "url": "https://www.xataka.com/feed",
                "category": "Tecnolog√≠a"
            }
        ]
        
        # Palabras clave para filtrar contenido relevante (en espa√±ol e ingl√©s)
        self.keywords = [
            # T√©rminos en espa√±ol
            "javascript", "react", "vue", "angular", "node.js", "python", "typescript",
            "css", "html", "desarrollo web", "frontend", "backend", "api", "base de datos",
            "git", "github", "docker", "kubernetes", "aws", "azure", "next.js", "nuxt",
            "svelte", "tailwind", "bootstrap", "webpack", "vite", "npm", "yarn",
            "programaci√≥n", "c√≥digo", "desarrollo de software", "devops", "aprendizaje autom√°tico",
            "inteligencia artificial", "blockchain", "desarrollo m√≥vil", "ios", "android",
            "tutorial", "curso", "aprender", "tecnolog√≠a", "programador", "desarrollador",
            "aplicaci√≥n", "web", "m√≥vil", "servidor", "cliente", "framework", "librer√≠a",
            "algoritmo", "estructura de datos", "patrones de dise√±o", "arquitectura",
            "testing", "pruebas", "debugging", "depuraci√≥n", "optimizaci√≥n", "performance",
            "seguridad", "autenticaci√≥n", "autorizaci√≥n", "criptograf√≠a", "https", "ssl",
            "responsive", "adaptativo", "ux", "ui", "dise√±o", "usabilidad", "accesibilidad",
            # T√©rminos en ingl√©s (por si acaso)
            "web development", "frontend", "backend", "database", "programming", "coding",
            "software development", "machine learning", "artificial intelligence", "mobile development"
        ]
    
    def load_processed_news(self):
        """Cargar lista de noticias ya procesadas"""
        if self.processed_file.exists():
            with open(self.processed_file, 'r', encoding='utf-8') as f:
                return set(json.load(f))
        return set()
    
    def save_processed_news(self, processed_set):
        """Guardar lista de noticias procesadas"""
        with open(self.processed_file, 'w', encoding='utf-8') as f:
            json.dump(list(processed_set), f, ensure_ascii=False, indent=2)
    
    def is_relevant_content(self, title, summary, content=""):
        """Verificar si el contenido es relevante para desarrollo"""
        text = f"{title} {summary} {content}".lower()
        return any(keyword.lower() in text for keyword in self.keywords)
    
    def clean_text(self, text):
        """Limpiar y formatear texto"""
        if not text:
            return ""
        
        # Remover HTML tags
        text = re.sub(r'<[^>]+>', '', text)
        # Limpiar caracteres especiales
        text = re.sub(r'[^\w\s\-.,!?]', '', text)
        # Normalizar espacios
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def is_spanish_content(self, text):
        """Verificar si el contenido est√° en espa√±ol"""
        if not text:
            return False
        
        # Palabras comunes en espa√±ol
        spanish_words = [
            "el", "la", "de", "que", "y", "a", "en", "un", "es", "se", "no", "te", "lo", "le",
            "da", "su", "por", "son", "con", "para", "al", "del", "los", "las", "una", "como",
            "m√°s", "pero", "sus", "todo", "esta", "sobre", "entre", "cuando", "muy", "sin",
            "hasta", "desde", "donde", "quien", "cual", "c√≥mo", "porque", "aunque", "tambi√©n",
            "desarrollo", "programaci√≥n", "aplicaci√≥n", "tecnolog√≠a", "software", "c√≥digo",
            "tutorial", "curso", "aprender", "programador", "desarrollador", "web", "m√≥vil"
        ]
        
        text_lower = text.lower()
        spanish_count = sum(1 for word in spanish_words if word in text_lower)
        
        # Si tiene al menos 3 palabras en espa√±ol, considerarlo espa√±ol
        return spanish_count >= 3
    
    def generate_slug(self, title):
        """Generar slug √∫nico para el archivo"""
        # Mapeo de caracteres con acentos a sin acentos
        accent_map = {
            '√°': 'a', '√†': 'a', '√§': 'a', '√¢': 'a', '√£': 'a', '√•': 'a',
            '√©': 'e', '√®': 'e', '√´': 'e', '√™': 'e',
            '√≠': 'i', '√¨': 'i', '√Ø': 'i', '√Æ': 'i',
            '√≥': 'o', '√≤': 'o', '√∂': 'o', '√¥': 'o', '√µ': 'o',
            '√∫': 'u', '√π': 'u', '√º': 'u', '√ª': 'u',
            '√Ω': 'y', '√ø': 'y',
            '√±': 'n', '√ß': 'c',
            '√Å': 'A', '√Ä': 'A', '√Ñ': 'A', '√Ç': 'A', '√É': 'A', '√Ö': 'A',
            '√â': 'E', '√à': 'E', '√ã': 'E', '√ä': 'E',
            '√ç': 'I', '√å': 'I', '√è': 'I', '√é': 'I',
            '√ì': 'O', '√í': 'O', '√ñ': 'O', '√î': 'O', '√ï': 'O',
            '√ö': 'U', '√ô': 'U', '√ú': 'U', '√õ': 'U',
            '√ù': 'Y', '≈∏': 'Y',
            '√ë': 'N', '√á': 'C'
        }
        
        # Convertir acentos a caracteres normales
        slug = title.lower()
        for accent, normal in accent_map.items():
            slug = slug.replace(accent, normal)
        
        # Limpiar t√≠tulo para slug
        slug = re.sub(r'[^\w\s-]', '', slug)
        slug = re.sub(r'[-\s]+', '-', slug)
        slug = slug.strip('-')
        
        # Limitar longitud del slug
        if len(slug) > 50:
            slug = slug[:50].rstrip('-')
        
        # Agregar timestamp para unicidad
        timestamp = datetime.now().strftime("%Y%m%d")
        return f"{slug}-{timestamp}"
    
    def fetch_rss_news(self):
        """Obtener noticias de feeds RSS"""
        all_news = []
        
        for feed_config in self.rss_feeds:
            try:
                print(f"üì° Obteniendo noticias de {feed_config['name']}...")
                
                # Parsear RSS feed
                feed = feedparser.parse(feed_config['url'])
                
                for entry in feed.entries[:5]:  # Solo las 5 m√°s recientes
                    # Extraer informaci√≥n
                    title = self.clean_text(entry.title)
                    summary = self.clean_text(entry.get('summary', ''))[:200] + "..."
                    content = self.clean_text(entry.get('content', [{}])[0].get('value', ''))[:500] + "..."
                    
                    # Verificar si es contenido relevante Y en espa√±ol
                    if not self.is_relevant_content(title, summary, content):
                        continue
                    
                    # Verificar que el contenido est√© en espa√±ol
                    if not self.is_spanish_content(f"{title} {summary} {content}"):
                        print(f"‚ö†Ô∏è  Saltando contenido no en espa√±ol: {title[:50]}...")
                        continue
                    
                    news_item = {
                        'title': title,
                        'summary': summary,
                        'url': entry.link,
                        'published': entry.get('published_parsed', None),
                        'source': feed_config['name'],
                        'category': feed_config['category'],
                        'content': content
                    }
                    
                    all_news.append(news_item)
                    time.sleep(0.5)  # Rate limiting
                    
            except Exception as e:
                print(f"‚ùå Error obteniendo {feed_config['name']}: {e}")
                continue
        
        return all_news
    
    def generate_mdx_content(self, news_item):
        """Generar contenido MDX para la noticia"""
        # Formatear fecha
        if news_item['published']:
            pub_date = datetime(*news_item['published'][:6]).strftime("%Y-%m-%d")
        else:
            pub_date = datetime.now().strftime("%Y-%m-%d")
        
        # Generar slug
        slug = self.generate_slug(news_item['title'])
        
        # Cargar template
        template_path = self.base_dir / "scripts" / "news-template.mdx"
        if template_path.exists():
            with open(template_path, 'r', encoding='utf-8') as f:
                template = f.read()
        else:
            # Template por defecto si no existe el archivo
            template = """---
title: "{{title}}"
summary: "{{summary}}"
publishedAt: "{{publishedAt}}"
tag: "{{category}}"
source: "{{source}}"
originalUrl: "{{originalUrl}}"
autoGenerated: true
---

## üì∞ {{title}}

**üì° Fuente:** {{source}}  
**üè∑Ô∏è Categor√≠a:** {{category}}  
**üìÖ Fecha original:** {{publishedAt}}

### üìù Resumen
{{summary}}

### üìñ Contenido
{{content}}

### üîó Acceso al Art√≠culo Original
<div style="text-align: center; margin: 2rem 0;">
  <a href="{{originalUrl}}" target="_blank" rel="noopener noreferrer" 
     style="display: inline-block; background: #007bff; color: white; padding: 12px 24px; 
            text-decoration: none; border-radius: 8px; font-weight: bold;">
    üìñ Leer art√≠culo completo en {{source}}
  </a>
</div>

---
*Este art√≠culo fue agregado autom√°ticamente desde {{source}} y traducido al espa√±ol.*"""
        
        # Reemplazar variables en el template
        content = template.replace("{{title}}", news_item['title'])
        content = content.replace("{{summary}}", news_item['summary'])
        content = content.replace("{{publishedAt}}", pub_date)
        content = content.replace("{{category}}", news_item['category'])
        content = content.replace("{{source}}", news_item['source'])
        content = content.replace("{{originalUrl}}", news_item['url'])
        content = content.replace("{{content}}", news_item['content'])
        content = content.replace("{{currentDate}}", datetime.now().strftime("%Y-%m-%d"))
        
        # Limpiar caracteres problem√°ticos que pueden causar problemas de redirecci√≥n
        content = content.replace('\r\n', '\n').replace('\r', '\n')
        
        return content, slug
    
    def create_mdx_file(self, content, slug):
        """Crear archivo MDX"""
        filename = f"{slug}.mdx"
        filepath = self.posts_dir / filename
        
        # Verificar si el archivo ya existe
        if filepath.exists():
            print(f"‚ö†Ô∏è  El archivo {filename} ya existe, saltando...")
            return False
        
        # Asegurar que el directorio existe
        self.posts_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"‚úÖ Creado: {filename}")
            return True
        except Exception as e:
            print(f"‚ùå Error creando {filename}: {e}")
            return False
    
    def run(self):
        """Ejecutar el scraper"""
        print("üöÄ Iniciando scraper de noticias de desarrollo...")
        
        # Cargar noticias ya procesadas
        processed = self.load_processed_news()
        
        # Obtener nuevas noticias
        news_items = self.fetch_rss_news()
        
        # Filtrar noticias ya procesadas
        new_news = []
        for item in news_items:
            # Crear hash √∫nico para la noticia
            news_hash = hashlib.md5(f"{item['title']}{item['url']}".encode()).hexdigest()
            
            if news_hash not in processed:
                new_news.append((item, news_hash))
        
        print(f"üìä Encontradas {len(new_news)} noticias nuevas")
        
        # Procesar m√°ximo 3 noticias por ejecuci√≥n
        created_count = 0
        for item, news_hash in new_news[:self.max_posts_per_run]:
            try:
                content, slug = self.generate_mdx_content(item)
                
                if self.create_mdx_file(content, slug):
                    processed.add(news_hash)
                    created_count += 1
                    
            except Exception as e:
                print(f"‚ùå Error procesando noticia: {e}")
                continue
        
        # Guardar noticias procesadas
        self.save_processed_news(processed)
        
        print(f"üéâ Proceso completado. Se crearon {created_count} nuevos posts.")
        return created_count > 0

if __name__ == "__main__":
    scraper = NewsScraper()
    scraper.run()
